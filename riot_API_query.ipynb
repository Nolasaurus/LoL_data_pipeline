{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# league IDs\n",
    "# https://canisback.com/leagueId/\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://canisback.com/leagueId/league_na1.csv'\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# Save the response content to a file\n",
    "with open('league_na1.csv', 'w') as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "na1_csv = pd.read_csv('league_na1.csv')\n",
    "league_dict = {}\n",
    "\n",
    "tiers = na1_csv.tier.unique()\n",
    "\n",
    "for tier in tiers: \n",
    "    leagues_in_tier = na1_csv[na1_csv['tier'] == tier]\n",
    "    league_dict[tier] = leagues_in_tier\n",
    "\n",
    "# Rate Limits:\n",
    "# 20 requests every 1 seconds(s)\n",
    "# 100 requests every 2 minutes(s)\n",
    "\n",
    "\n",
    "# TODO: def checkRateLimit():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_id = '6d40beb9-9799-461c-b64e-53ad7c5f8a20'\n",
    "\n",
    "from get_summoner_ids_from_league_id import get_summoner_ids_from_league_id\n",
    "summoner_ids = get_summoner_ids_from_league_id(league_id)\n",
    "\n",
    "from get_puuid_by_summon_id import get_puuid_by_summon_id\n",
    "puuid = get_puuid_by_summon_id(summoner_ids[0]) \n",
    "\n",
    "from get_match_ids_by_puuid import get_match_ids_by_puuid\n",
    "match_ids = get_match_ids_by_puuid(puuid)\n",
    "\n",
    "from get_match_timeline import get_match_timeline\n",
    "match_timeline = get_match_timeline(match_ids[0])\n",
    "\n",
    "from extract_events_from_timeline import extract_events_from_timeline\n",
    "timeline_events = extract_events_from_timeline(match_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity of game_event_df is: 86.20%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "game_event_df = timeline_events\n",
    "# Count the number of missing values in each column\n",
    "missing_values = game_event_df.isna().sum()\n",
    "\n",
    "# Calculate the total number of elements in the DataFrame\n",
    "total_elements = np.prod(game_event_df.shape)\n",
    "\n",
    "# Calculate the sparsity as the proportion of missing values\n",
    "sparsity = missing_values.sum() / total_elements\n",
    "\n",
    "# Calculate the sparsity percentage\n",
    "sparsity_percentage = sparsity * 100\n",
    "\n",
    "print(f\"The sparsity of game_event_df is: {sparsity_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'levelUpType',\n",
       " 'wardType',\n",
       " 'assistingParticipantIds',\n",
       " 'position',\n",
       " 'victimDamageDealt',\n",
       " 'victimDamageReceived',\n",
       " 'killType',\n",
       " 'laneType',\n",
       " 'monsterSubType',\n",
       " 'monsterType',\n",
       " 'buildingType',\n",
       " 'towerType']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline_events.dtypes[timeline_events.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST: Put timeline_events in SQL as single table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optimize sql schema\n",
    "# TODO: switch to MySQL\n",
    "# TODO: connect to Azure/AWS/GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('LOL_API_data.db')\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute an SQL query to retrieve table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Fetch all the rows from the result set\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Process and print the retrieved table names\n",
    "for table in tables:\n",
    "    print(f\"Table: {table[0]}\")\n",
    "    cursor.execute(f\"SELECT * FROM {table[0]} LIMIT 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sci-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
